{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6076917b",
   "metadata": {},
   "source": [
    "# Econ 425T Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5b013",
   "metadata": {},
   "source": [
    "AUTHORï¼šRuoxuan Yan\n",
    "\n",
    "UID: 506082695"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a43c4",
   "metadata": {},
   "source": [
    "## 1. Least squares is MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b6d048",
   "metadata": {},
   "source": [
    "Because it's linear model with Gaussian errors,\n",
    "$$\n",
    "Y = \\beta_0X_0 + \\beta_1X_1 + ... + \\beta_kX_k + \\epsilon, \\epsilon \\sim N(0, \\sigma).\n",
    "$$\n",
    "\n",
    "The distribution of Y is\n",
    "$$N \\sim (\\beta_0X_0 + \\beta_1X_1 + ... + \\beta_kX_k, \\sigma).$$\n",
    "\n",
    "Log-likelihood function of $\\beta$s is\n",
    "\n",
    "$$\\begin{aligned}\n",
    "l(\\beta) &= \\log(\\prod_{i = 0}^{n}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(y_i-(\\beta_0x_{i0} + \\beta_1x_{i1} + ... + \\beta_kx_{ik}))^2}{2\\sigma^2}}) \\\\\n",
    "&=n\\log(\\frac{1}{\\sqrt{2\\pi}\\sigma}) + \\sum_{i = 0}^{n}\\frac{-(y_i-(\\beta_0x_{i0} + \\beta_1x_{i1} + ... + \\beta_kx_{ik}))^2}{2\\sigma^2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "So MLE is to maximize log-likelihood function and is equal to minimize $(y_i-(\\beta_0x_{i0} + \\beta_1x_{i1} + ... + \\beta_kx_{ik}))^2$, which is the same equation as least squares estimation. So least squares is MLE. \n",
    "\n",
    "For the AIC criterion: \n",
    "$$\\begin{aligned}\n",
    "\\text{AIC} &= -  2 \\log L + 2d \\\\\n",
    "&= -2n\\log(\\frac{1}{\\sqrt{2\\pi}\\sigma}) + \\sum_{i = 0}^{n}\\frac{(y_i-(\\beta_0x_{i0} + \\beta_1x_{i1} + ... + \\beta_kx_{ik}))^2}{\\sigma^2} + 2d \\\\\n",
    "&= -2n\\log(\\frac{1}{\\sqrt{2\\pi}\\sigma}) + \\frac{1}{\\sigma^2}(\\sum_{i = 0}^{n}(y_i-(\\beta_0x_{i0} + \\beta_1x_{i1} + ... + \\beta_kx_{ik}))^2 + 2d \\sigma^2).\n",
    "\\end{aligned}$$\n",
    "\n",
    "For Mallow's $C_p$:\n",
    "$$\\begin{aligned}\n",
    "C_p &= \\frac{1}{n} (\\text{RSS} + 2d \\hat{\\sigma}^2) \\\\\n",
    "&= \\frac{1}{n} (\\sum_{i = 0}^{n}(y_i-(\\beta_0x_{i0} + \\beta_1x_{i1} + ... + \\beta_kx_{ik}))^2 + 2d \\hat{\\sigma}^2).\n",
    "\\end{aligned}$$\n",
    "\n",
    "So the smaller value of $\\sum_{i = 0}^{n}(y_i-(\\beta_0x_{i0} + \\beta_1x_{i1} + ... + \\beta_kx_{ik}))^2 + 2d \\hat{\\sigma}^2$ means a smaller value of AIC and Mallow's $C_p$. $C_p$ and AIC are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b03ca2",
   "metadata": {},
   "source": [
    "## 2. ISL Exercise 6.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87232873",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed76921",
   "metadata": {},
   "source": [
    "Best subset with k predictors has the smallest training RSS. Because best subset selection algorithm is to select the model with smallest RSS among all the models with k predictors. But for forward stepwise and backward stepwise selection, they both choose the best model based on the model in the previous step with k-1 and k+1 predictors after adding or subtracting one predictor. So the model selected by forward stepwise and backward stepwise selection may not be the model with smallest training RSS among all models with k predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30cdea",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc510f",
   "metadata": {},
   "source": [
    "We cannot tell which of the three models with k predictors has the smallest test RSS, it depends on the test data. All three models have the chance to generate the smallest test RSS with different test data. But because best subset selection algorithm takes into account more information than the other two methods, it may have a larger probability to generate smallest test RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57212a1d",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4e3f9",
   "metadata": {},
   "source": [
    "i. True \n",
    "\n",
    "ii. True \n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. False \n",
    "\n",
    "v. False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a36fd4",
   "metadata": {},
   "source": [
    "## 3. ISL Exercise 6.6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d75fc2",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613162cc",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. True (Steadily decrease.)\n",
    "\n",
    "v. False\n",
    "\n",
    "Because as we increase s from 0, the model flexibility will increase. So it can fit the training data well and decrease the training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994ac63",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d18952f",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. True (Decrease initially, and then eventually start increasing in a U shape.)\n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. False \n",
    "\n",
    "v. False\n",
    "\n",
    "Because as we increase s from 0, the model flexibility will increase. So it can take more information from the training data and become more precision in predicting the testing data initially, and the test RSS will decrease at first. But when model flexibility continues to increase, it will generate overfitting problem and thus increase the test RSS to generate a U shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae361ad",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfb59a",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. True (Steadily increase.)\n",
    "\n",
    "iv. False \n",
    "\n",
    "v. False\n",
    "\n",
    "Because as the model flexibility increases, the variance of the model will increase as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd1c72",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482437f",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. True (Steadily decrease.) \n",
    "\n",
    "v. False\n",
    "\n",
    "Because as the model flexibility increases, it takes into account more information from the training data. So the expected value of the estimation will be closer to the true value and squared bias steadily decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4827",
   "metadata": {},
   "source": [
    "### (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019da6f",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. False \n",
    "\n",
    "v. True (Remain constant.)\n",
    "\n",
    "Because the irreducible error is irrelavant to the model, when we increase s from 0 which increases model flexibility, the irreducible error just remain constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ec4c2",
   "metadata": {},
   "source": [
    "## 4. ISL Exercise 6.6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad620c",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee268d1",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. True (Steadily increase.)\n",
    "\n",
    "iv. False \n",
    "\n",
    "v. False\n",
    "\n",
    "Because as we increase $\\lambda$ from 0, the model flexibility will decrease. So it has more constraint and fits the training data worse and thus increase the training RSS steadily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e9a38",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef1d69",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. True (Decrease initially, and then eventually start increasing in a U shape.)\n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. False \n",
    "\n",
    "v. False\n",
    "\n",
    "Because as we increase $\\lambda$ from 0, the model flexibility will decrease. So it will decrease the overfitting problem at first and the test RSS will decrease. But when model flexibility continues to decrease, it lose lots of information from the training data and become less precise in predicting the test data and thus increase the test RSS to generate a U shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f58aeb",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9017aa9",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. True (Steadily decrease.) \n",
    "\n",
    "v. False\n",
    "\n",
    "Because as the model flexibility decreases, the variance of the model will decrease as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06374a19",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8f2bd",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. True (Steadily increase.)\n",
    "\n",
    "iv. False \n",
    "\n",
    "v. False\n",
    "\n",
    "Because as the model flexibility decreases, it takes into account less information from the training data. So the expected value of the estimation will be less close to the true value and squared bias steadily increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22dad2",
   "metadata": {},
   "source": [
    "### (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99136757",
   "metadata": {},
   "source": [
    "i. False \n",
    "\n",
    "ii. False \n",
    "\n",
    "iii. False \n",
    "\n",
    "iv. False\n",
    "\n",
    "v. True (Remain constant.)\n",
    "\n",
    "Because the irreducible error is irrelavant to the model, when we increase $\\lambda$ from 0 which decreases model flexibility, the irreducible error just remain constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bba032",
   "metadata": {},
   "source": [
    "## 5. ISL Exercise 6.6.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f25a47",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83cbcbc",
   "metadata": {},
   "source": [
    "Because in this setting $\\hat \\beta_0 = 0$ and $x_{11} = x_{12}$, $x_{21} = x_{22}$. And $y_1 + y_2 = 0$ and $x_{11} + x_{21} = 0$ and $x_{12} + x_{22} = 0$. Assume that $x_{11} = x_{12} = x_1$, $x_{21} = x_{22} = x_2$. The ridge regression optimization problem is to minimize $\\text{RSS} + \\lambda \\sum_{j=1}^p \\beta_j^2.$ Use the parameters in this setting, the objective function we need to minimize is:\n",
    "$$\n",
    "(y_1 - \\hat\\beta_1x_1 - \\hat\\beta_2x_1)^2 + (y_2 - \\hat\\beta_1x_2 - \\hat\\beta_2x_2)^2 + \\lambda(\\hat\\beta_1^2 + \\hat\\beta_2^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd7a35",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aeda91",
   "metadata": {},
   "source": [
    "Take derivative of the funtion in (a) with respect to $\\hat\\beta_1$ and $\\hat\\beta_2$:\n",
    "$$\n",
    "2(y_1 - \\hat\\beta_1x_1 - \\hat\\beta_2x_1)x_1 + 2(y_2 - \\hat\\beta_1x_2 - \\hat\\beta_2x_2)x_2 + 2\\lambda\\hat\\beta_1 = 0 \\\\\n",
    "2(y_1 - \\hat\\beta_1x_1 - \\hat\\beta_2x_1)x_1 + 2(y_2 - \\hat\\beta_1x_2 - \\hat\\beta_2x_2)x_2 + 2\\lambda\\hat\\beta_2 = 0\n",
    "$$\n",
    "\n",
    "By subtracting two equations above we get:\n",
    "$$\n",
    "2\\lambda\\hat\\beta_1 - 2\\lambda\\hat\\beta_2 = 0 \\\\\n",
    "\\hat\\beta_1 = \\hat\\beta_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8bc64",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3b59e",
   "metadata": {},
   "source": [
    "The lasso regression optimization problem is to minimize $\\text{RSS} + \\lambda \\sum_{j=1}^p |\\beta_j|$. Use the parameters in this setting, the objective function we need to minimize is:\n",
    "$$\n",
    "(y_1 - \\hat\\beta_1x_1 - \\hat\\beta_2x_1)^2 + (y_2 - \\hat\\beta_1x_2 - \\hat\\beta_2x_2)^2 + \\lambda(|\\hat\\beta_1| + |\\hat\\beta_2|)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175063e4",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ced32",
   "metadata": {},
   "source": [
    "Because $y_1 + y_2 = 0$ and $x_{11} + x_{21} = 0$ and $x_{12} + x_{22} = 0$, our goal is to minimize $$2(y_1 - \\hat\\beta_1x_1 - \\hat\\beta_2x_1)^2 + \\lambda(|\\hat\\beta_1| + |\\hat\\beta_2|).$$\n",
    "\n",
    "Also this problem can be written as to minimize $$2(y_1 - \\hat\\beta_1x_1 - \\hat\\beta_2x_1)^2$$ subject to the constraint $$|\\hat\\beta_1| + |\\hat\\beta_2| \\le s.$$\n",
    "\n",
    "When $\\hat\\beta_1 + \\hat\\beta_2 = \\frac{y_1}{x_1}$, the objective function achieves its minimum value $0$. And the constraint of $\\hat\\beta_1$ and $\\hat\\beta_2$ forms a diamond area around $0$ with two edges $\\hat\\beta_1 + \\hat\\beta_2 = s$ and $\\hat\\beta_1 + \\hat\\beta_2 = -s$ having the same slope as the set of solutions for the objective function. So when these lines coincide, the entire edge $\\hat\\beta_1 + \\hat\\beta_2 = s, \\hat\\beta_1,\\hat\\beta_2 \\geq 0$ and $\\hat\\beta_1 + \\hat\\beta_2 = -s, \\hat\\beta_1,\\hat\\beta_2 \\le 0$ are the solutions for this problem. So there are many possible solutions to the optimization problem instead of one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc71e17b",
   "metadata": {},
   "source": [
    "## 6. ISL Exercise 6.6.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c862ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c06cb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "1    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "2    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "3    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "4    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "5    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "502  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "503  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "504  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "505  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "506  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio  lstat  medv  \n",
       "1       15.3   4.98  24.0  \n",
       "2       17.8   9.14  21.6  \n",
       "3       17.8   4.03  34.7  \n",
       "4       18.7   2.94  33.4  \n",
       "5       18.7   5.33  36.2  \n",
       "..       ...    ...   ...  \n",
       "502     21.0   9.67  22.4  \n",
       "503     21.0   9.08  20.6  \n",
       "504     21.0   5.64  23.9  \n",
       "505     21.0   6.48  22.0  \n",
       "506     21.0   7.88  11.9  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data\n",
    "url = \"https://raw.githubusercontent.com/ucla-econ-425t/2023winter/master/slides/data/Boston.csv\"\n",
    "s = requests.get(url).content\n",
    "Boston = pd.read_csv(io.StringIO(s.decode('utf-8')), index_col = 0)\n",
    "Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027c7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 506 entries, 1 to 506\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  lstat    506 non-null    float64\n",
      " 12  medv     506 non-null    float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 55.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Numerical summaries\n",
    "Boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f90066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       lstat  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
       "\n",
       "             medv  \n",
       "count  506.000000  \n",
       "mean    22.532806  \n",
       "std      9.197104  \n",
       "min      5.000000  \n",
       "25%     17.025000  \n",
       "50%     21.200000  \n",
       "75%     25.000000  \n",
       "max     50.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the data\n",
    "Boston.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381b362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (404, 13)\n",
      "Testing set shape: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Boston_train, Boston_test = train_test_split(\n",
    "  Boston, \n",
    "  train_size = 0.8,\n",
    "  random_state = 425, # seed\n",
    "  )\n",
    "print('Training set shape:', Boston_train.shape)\n",
    "print('Testing set shape:', Boston_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6bfaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y\n",
    "\n",
    "# Training X and y\n",
    "X_train = Boston_train.drop('crim', axis = 1)\n",
    "y_train = Boston_train.crim\n",
    "\n",
    "# Testing X and y\n",
    "X_test = Boston_test.drop('crim', axis = 1)\n",
    "y_test = Boston_test.crim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3e8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Standardization transformer\n",
    "scalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc1340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Models\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "LS = LinearRegression()\n",
    "\n",
    "lasso = Lasso(max_iter = 10000)\n",
    "\n",
    "ridge = Ridge(max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8759eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle the preprocessing step and model.\n",
    "pipe1 = Pipeline(steps = [\n",
    "  (\"std_tf\", scalar), \n",
    "  (\"model\", lasso)\n",
    "  ])\n",
    "\n",
    "pipe2 = Pipeline(steps = [\n",
    "  (\"std_tf\", scalar), \n",
    "  (\"model\", ridge)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e2ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the grid for tuning in the range of 10^(-3) to 10^2\n",
    "alphas = np.logspace(start = -3, stop = 2, base = 10, num = 100)\n",
    "tuned_parameters = {\"model__alpha\": alphas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f5d35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up CV partitions and CV criterion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up CV\n",
    "n_folds = 5\n",
    "search1 = GridSearchCV(\n",
    "  pipe1, \n",
    "  tuned_parameters, \n",
    "  cv = n_folds, \n",
    "  scoring = \"neg_root_mean_squared_error\",\n",
    "  # Refit the best model on the whole data set\n",
    "  refit = True \n",
    "  )\n",
    "\n",
    "search2 = GridSearchCV(\n",
    "  pipe2, \n",
    "  tuned_parameters, \n",
    "  cv = n_folds, \n",
    "  scoring = \"neg_root_mean_squared_error\",\n",
    "  # Refit the best model on the whole data set\n",
    "  refit = True \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a7a3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('std_tf', StandardScaler()),\n",
       "                                       ('model', Lasso(max_iter=10000))]),\n",
       "             param_grid={'model__alpha': array([1.00000000e-03, 1.12332403e-03, 1.26185688e-03, 1.41747416e-03,\n",
       "       1.59228279e-03, 1.78864953e-03, 2.00923300e-03, 2.25701972e-03,\n",
       "       2.53536449e-03, 2.84803587e-03, 3.19926714e-03, 3.59381366e-03,\n",
       "       4.03701726e-03, 4.53487851e-03,...\n",
       "       6.89261210e+00, 7.74263683e+00, 8.69749003e+00, 9.77009957e+00,\n",
       "       1.09749877e+01, 1.23284674e+01, 1.38488637e+01, 1.55567614e+01,\n",
       "       1.74752840e+01, 1.96304065e+01, 2.20513074e+01, 2.47707636e+01,\n",
       "       2.78255940e+01, 3.12571585e+01, 3.51119173e+01, 3.94420606e+01,\n",
       "       4.43062146e+01, 4.97702356e+01, 5.59081018e+01, 6.28029144e+01,\n",
       "       7.05480231e+01, 7.92482898e+01, 8.90215085e+01, 1.00000000e+02])},\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit CV\n",
    "search1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99279d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('std_tf', StandardScaler()),\n",
       "                                       ('model', Ridge(max_iter=10000))]),\n",
       "             param_grid={'model__alpha': array([1.00000000e-03, 1.12332403e-03, 1.26185688e-03, 1.41747416e-03,\n",
       "       1.59228279e-03, 1.78864953e-03, 2.00923300e-03, 2.25701972e-03,\n",
       "       2.53536449e-03, 2.84803587e-03, 3.19926714e-03, 3.59381366e-03,\n",
       "       4.03701726e-03, 4.53487851e-03,...\n",
       "       6.89261210e+00, 7.74263683e+00, 8.69749003e+00, 9.77009957e+00,\n",
       "       1.09749877e+01, 1.23284674e+01, 1.38488637e+01, 1.55567614e+01,\n",
       "       1.74752840e+01, 1.96304065e+01, 2.20513074e+01, 2.47707636e+01,\n",
       "       2.78255940e+01, 3.12571585e+01, 3.51119173e+01, 3.94420606e+01,\n",
       "       4.43062146e+01, 4.97702356e+01, 5.59081018e+01, 6.28029144e+01,\n",
       "       7.05480231e+01, 7.92482898e+01, 8.90215085e+01, 1.00000000e+02])},\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e7e479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso best CV RMSE: 7.072469903671658\n"
     ]
    }
   ],
   "source": [
    "# Plot the CV results for lasso regression\n",
    "cv_res1 = pd.DataFrame({\n",
    "  \"alpha\": alphas,\n",
    "  \"rmse\": -search1.cv_results_[\"mean_test_score\"]\n",
    "  })\n",
    "\n",
    "plt.figure()\n",
    "sns.relplot(\n",
    "  data = cv_res1,\n",
    "  x = \"alpha\",\n",
    "  y = \"rmse\"\n",
    "  ).set(\n",
    "    xlabel = \"alpha\",\n",
    "    ylabel = \"CV RMSE\",\n",
    "    xscale = \"log\"\n",
    ");\n",
    "plt.show()\n",
    "\n",
    "# Get the best CV RMSE \n",
    "print('Lasso best CV RMSE:', -search1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3d03da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge best CV RMSE: 7.082722382699549\n"
     ]
    }
   ],
   "source": [
    "# Plot the CV results for ridge regression\n",
    "cv_res2 = pd.DataFrame({\n",
    "  \"alpha\": alphas,\n",
    "  \"rmse\": -search2.cv_results_[\"mean_test_score\"]\n",
    "  })\n",
    "\n",
    "plt.figure()\n",
    "sns.relplot(\n",
    "  data = cv_res2,\n",
    "  x = \"alpha\",\n",
    "  y = \"rmse\"\n",
    "  ).set(\n",
    "    xlabel = \"alpha\",\n",
    "    ylabel = \"CV RMSE\",\n",
    "    xscale = \"log\"\n",
    ");\n",
    "plt.show()\n",
    "\n",
    "# Get the best CV RMSE \n",
    "print('Ridge best CV RMSE:', -search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82d40fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso prediction RMSE on the testing set: 2.7957851285333697\n",
      "Ridge prediction RMSE on the testing set: 2.770139139847998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Get the final prediction RMSE on the testing set\n",
    "mse1 = mean_squared_error(y_test, search1.best_estimator_.predict(X_test), squared = False)\n",
    "mse2 = mean_squared_error(y_test, search2.best_estimator_.predict(X_test), squared = False)\n",
    "\n",
    "print('Lasso prediction RMSE on the testing set:', mse1)\n",
    "print('Ridge prediction RMSE on the testing set:', mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f702e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares CV RMSE: 7.107116601569681\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV RMSE and test RMSE for least squares\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "LS_RMSE = -cross_val_score(LS, X_train, y_train, cv=5, \n",
    "                        scoring = \"neg_root_mean_squared_error\").mean()\n",
    "print('Least squares CV RMSE:', LS_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8420dd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares prediction RMSE on the testing set: 2.9251642262456703\n"
     ]
    }
   ],
   "source": [
    "# Get the final prediction RMSE on the testing set\n",
    "reg = LS.fit(X_train, y_train)\n",
    "mse3 = mean_squared_error(y_test, reg.predict(X_test), squared = False)\n",
    "print('Least squares prediction RMSE on the testing set:', mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e5747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Method   CV RMSE  Test RMSE\n",
      "0     LS  7.107117   2.925164\n",
      "1  Ridge  7.082722   2.770139\n",
      "2  Lasso  7.072470   2.795785\n"
     ]
    }
   ],
   "source": [
    "# Report final results\n",
    "result = {\n",
    "    'Method': ['LS', 'Ridge', 'Lasso'],\n",
    "    'CV RMSE': [LS_RMSE, -search2.best_score_, -search1.best_score_],\n",
    "    'Test RMSE': [mse3, mse2, mse1]\n",
    "}\n",
    "\n",
    "print(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52acd6c",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b79432",
   "metadata": {},
   "source": [
    "The results for least squares, ridge, and lasso are show from the analysis above. The cross-validation root mean squared errors for these models are 7.11, 7.08 and 7.07 respectively. The test RMSE root mean squared errors for these models are 2.93, 2.77 and 2.80 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd246a8b",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e850821",
   "metadata": {},
   "source": [
    "From the analysis above, it seems that both ridge and lasso perform well on this data set. Among all three methods, lasso generate the smallest CV RMSE and ridge generate the smallest test RMSE, and the differences of CV RMSE and test RMSE for these two methods are really small. So both ridge and lasso perform well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240de29",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba0617a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.29998547e-02, -4.27567223e-02, -4.55321221e-01, -1.08257481e+01,\n",
       "        8.22280393e-01,  1.79052700e-03, -1.10680162e+00,  6.60688548e-01,\n",
       "       -5.73858498e-03, -3.23053670e-01,  1.25645558e-01, -2.57576157e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficient for least squares\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4f54ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88611358, -0.27557553, -0.08549562, -0.54104411,  0.32416901,\n",
       "        0.        , -1.55024072,  4.72158568, -0.        , -0.37408799,\n",
       "        0.85341566, -1.74381724])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficient for Lasso\n",
    "search1.best_estimator_.named_steps.model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8143e203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95442315, -0.44440035, -0.14401366, -0.73880939,  0.50267053,\n",
       "        0.04702148, -1.8039775 ,  4.41468487,  0.26020818, -0.44977901,\n",
       "        1.04129489, -1.873062  ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficient for Ridge\n",
    "search2.best_estimator_.named_steps.model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacad35e",
   "metadata": {},
   "source": [
    "Because all the coefficients for ridge and least squares regression methods are not 0, they both involve all of the features in the data set. But two of the coefficients for lasso regression method are 0, it doesn't involve all of the features in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3eb97e",
   "metadata": {},
   "source": [
    "## 7. ISL Exercise 5.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf70f8",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8906b8",
   "metadata": {},
   "source": [
    "The probability that the first bootstrap observation is not the jth observation from the original sample is one minus the probability that the first bootstrap observation is the jth observation from the original sample: $1 - \\frac{1}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc8352",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387338d4",
   "metadata": {},
   "source": [
    "Because each bootstrap data set is sampled with replacement from the original data set, so different observations are independent from each other. It's the same as the probability in question (a): $1 - \\frac{1}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0933ef",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e8234c",
   "metadata": {},
   "source": [
    "Because different observations are independent from each other, the probability that the jth observation is not in the bootstrap sample is the product of the probability that each bootstrap observation is not the jth observation: $(1 - \\frac{1}{n})^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fab937",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f8cf2",
   "metadata": {},
   "source": [
    "The probability that the jth observation is in the bootstrap sample equals to one minus the probability that the jth observation is not in the bootstrap sample: $1 - (1 - \\frac{1}{n})^n$. When $n = 5$, the probability is $1 - (1 - \\frac{1}{5})^5 = 0.672$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea29346",
   "metadata": {},
   "source": [
    "### (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434dd53",
   "metadata": {},
   "source": [
    "When $n = 100$, the probability is $1 - (1 - \\frac{1}{100})^{100} = 0.634$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3751a71",
   "metadata": {},
   "source": [
    "### (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc36ff",
   "metadata": {},
   "source": [
    "When $n = 10000$, the probability is $1 - (1 - \\frac{1}{10000})^{10000} = 0.632$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5ecf0",
   "metadata": {},
   "source": [
    "### (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52d070ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i + 1 for i in range(100000)]\n",
    "y = [1-(1-1/i)**i for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "228788a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee6361",
   "metadata": {},
   "source": [
    "The probability that the jth observation is in the bootstrap sample decreased sharply as n increases from 1 and then approaches a constant number around 0.632."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065267de",
   "metadata": {},
   "source": [
    "### (h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4da0f39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6355635563556356"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = [] \n",
    "for i in np.arange(1, 10000):\n",
    "    num += [np.sum(np.random.randint(low=1, high=101, size=100) == 4) > 0]\n",
    "np.mean(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7402e4",
   "metadata": {},
   "source": [
    "It is very close to the probability we calculated in question (e)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a5a0c",
   "metadata": {},
   "source": [
    "## 8. ISL Exercise 5.4.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639e207",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef610d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110698"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = Boston.medv.mean()\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe4b06",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2731f4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4088611474975351"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = Boston.medv.std()/np.sqrt(Boston.medv.count())\n",
    "sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d8b78",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8364d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40962587329577405"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Generate 1000 bootstrap samples\n",
    "bootstrapped_mean = []\n",
    "for i in range(1000):\n",
    "    bootstrapped_sample = resample(Boston.medv)\n",
    "    bootstrapped_mu = np.mean(bootstrapped_sample)\n",
    "    bootstrapped_mean.append(bootstrapped_mu)\n",
    "\n",
    "bs_std_mean = np.std(bootstrapped_mean)\n",
    "bs_std_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a33949",
   "metadata": {},
   "source": [
    "This is very close to the value in question (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e0042",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "313fe848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval for the mean: [21.694710357878286, 23.37090229034311]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap 95% confidence interval for the mean\n",
    "lb = mu - 2*bs_std\n",
    "hb = mu + 2*bs_std\n",
    "CI_bs = [lb, hb]\n",
    "print(\"95% Confidence interval for the mean:\", CI_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ada3a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval for the mean: (21.729528014578616, 23.33608463364278)\n"
     ]
    }
   ],
   "source": [
    "# T-test 95% confidence interval for the mean\n",
    "from scipy import stats\n",
    "\n",
    "alpha = 0.05\n",
    "mean = np.mean(Boston.medv) \n",
    "std_err = stats.sem(Boston.medv) \n",
    "df = len(Boston.medv) - 1 \n",
    "CI_ttest = stats.t.interval(1-alpha, df, loc=mean, scale=std_err)\n",
    "print(\"95% Confidence interval for the mean:\", CI_ttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c3039",
   "metadata": {},
   "source": [
    "We can see that they are very similar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb479b",
   "metadata": {},
   "source": [
    "### (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "414d109e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med = Boston.medv.median()\n",
    "med"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e5b46b",
   "metadata": {},
   "source": [
    "### (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71e5d220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3784803693720452"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 1000 bootstrap samples\n",
    "bootstrapped_median = []\n",
    "for i in range(1000):\n",
    "    bootstrapped_sample = resample(Boston.medv)\n",
    "    bootstrapped_med = np.median(bootstrapped_sample)\n",
    "    bootstrapped_median.append(bootstrapped_med)\n",
    "\n",
    "bs_std_med = np.std(bootstrapped_median)\n",
    "bs_std_med"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c3bad",
   "metadata": {},
   "source": [
    "The estimated standard error is smaller than the standard error for mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2574e22",
   "metadata": {},
   "source": [
    "### (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba3d4b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_pc = Boston.medv.quantile(0.1)\n",
    "ten_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149ab42",
   "metadata": {},
   "source": [
    "### (h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb9a6d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4710807149523317"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 1000 bootstrap samples\n",
    "bootstrapped_quantile = []\n",
    "for i in range(1000):\n",
    "    bootstrapped_sample = resample(Boston.medv)\n",
    "    bootstrapped_qt = np.quantile(bootstrapped_sample, 0.1)\n",
    "    bootstrapped_quantile.append(bootstrapped_qt)\n",
    "\n",
    "bs_std_qt = np.std(bootstrapped_quantile)\n",
    "bs_std_qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29cdf7",
   "metadata": {},
   "source": [
    "The estimated standard error is larger than the standard error for mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734f7b2",
   "metadata": {},
   "source": [
    "## 9. Bonus question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eafcdd",
   "metadata": {},
   "source": [
    " $\\operatorname{E}[R_{\\text{train}}(\\hat\\beta)] = \\operatorname{E}[\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat\\beta^T x_i)^2] = \\frac{1}{N} \\sum_{i=1}^N \\operatorname{E}[(y_i - \\hat\\beta^T x_i)^2]$\n",
    " \n",
    " $\\operatorname{E}[R_{\\text{test}}(\\hat\\beta)] = \\operatorname{E}[\\frac{1}{M} \\sum_{i=1}^M (\\tilde{y}_i - \\hat\\beta^T \\tilde{x}_i)^2] = \\frac{1}{M} \\sum_{i=1}^M \\operatorname{E}[(\\tilde{y}_i - \\hat\\beta^T \\tilde{x}_i)^2]$\n",
    " \n",
    " Because those data are i.i.d., $\\operatorname{E}[R_{\\text{train}}(\\hat\\beta)] = \\operatorname{E}[(y_i - \\hat\\beta^T x_i)^2]$ and $\\operatorname{E}[R_{\\text{test}}(\\hat\\beta)] = \\operatorname{E}[(\\tilde{y}_i - \\hat\\beta^T \\tilde{x}_i)^2]$.\n",
    " \n",
    " Because $\\hat\\beta$ is generated from least square estimation, for every possible value of $\\beta$ we can know that $\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat\\beta^T x_i)^2 \\le \\frac{1}{N} \\sum_{i=1}^N (y_i - \\beta^T x_i)^2$. So $\\operatorname{E}[(y_i - \\hat\\beta^T x_i)^2] \\le \\operatorname{E}[(y_i - \\beta^T x_i)^2]$.\n",
    " \n",
    " Suppose $\\beta = \\frac{1}{||X_i||^2}(Y_iX_i - \\tilde{Y}_jX_i + X_i\\tilde{X}_j^T\\hat\\beta)$, plug into the equation above we can get $\\operatorname{E}[(y_i - \\hat\\beta^T x_i)^2] \\le \\operatorname{E}[(\\tilde{y}_i - \\hat\\beta^T \\tilde{x}_i)^2]$.\n",
    "\n",
    "So $\\operatorname{E}[R_{\\text{train}}(\\hat{\\beta})] < \\operatorname{E}[R_{\\text{test}}(\\hat{\\beta})]$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
